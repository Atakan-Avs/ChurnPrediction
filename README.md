@"
# Telco Customer Churn Prediction


This project focuses on predicting **customer churn** using the Kaggle Telco Customer Churn dataset.  
The workflow covers **data cleaning, exploratory data analysis (EDA), machine learning modeling (Logistic Regression & Random Forest), and feature importance analysis**.

---

## ğŸ“Š Dataset
- **Source:** [Kaggle â€“ Telco Customer Churn](https://www.kaggle.com/blastchar/telco-customer-churn)
- **Rows:** 7,043 customers  
- **Columns:** 21 features (demographics, contract, services, charges) + target `Churn`

## ğŸ—‚ï¸ Project Structure

churn-project/
â”œâ”€ data/
â”‚ â”œâ”€ raw/
â”‚ â””â”€ processed/ # telco_clean.csv
â”œâ”€ notebooks/
â”‚ â”œâ”€ 01_load_data.py
â”‚ â”œâ”€ 02_eda.py
â”‚ â””â”€ 03_model.py
â”œâ”€ requirements.txt
â””â”€ README.md

ğŸ“Š Key Findings from EDA

Churn Rate: â‰ˆ 26.5%

Contract: Month-to-month contracts have the highest churn, while two-year contracts have the lowest.

Tenure: New customers are more likely to churn.

Monthly Charges: Higher monthly charges correlate with higher churn.

Payment Method: Customers paying via Electronic Check churn more.

ğŸ¤– Models & Results

Logistic Regression

Accuracy: ~79%

Recall (Churn=1): ~54%

Random Forest

Accuracy: ~79%

Recall (Churn=1): ~50%

âš ï¸ Note: Accuracy is high, but recall for churn cases is moderate, meaning some churned customers are missed.

â­ Feature Importance (Random Forest)

Top predictors influencing churn:

TotalCharges

tenure

MonthlyCharges

Contract (Month-to-month)

Contract (Two year)

OnlineSecurity (No)

TechSupport (No)

PaymentMethod (Electronic Check)

InternetService (Fiber optic)

OnlineBackup (No)

ğŸ“Œ Business Insights

High-risk customers: short-tenure, month-to-month contracts, high monthly charges, Electronic Check payments, no extra services.

Recommendations:

Offer loyalty discounts for new customers.

Encourage long-term contracts.

Bundle extra services (security, tech support) to reduce churn risk.

ğŸ”® Possible Improvements

Handle class imbalance with SMOTE or threshold tuning.

Try advanced models: XGBoost, LightGBM, Gradient Boosting.

Perform hyperparameter optimization (GridSearchCV, RandomizedSearchCV).

Deploy as an API using Flask/Django for real-time predictions.
